apiVersion: v1
kind: ConfigMap
metadata:
  name: demo-library-frontend-configs
  namespace: zim
data:
  botPolicies.yaml: |
    #
    # WARN: our custom rules are at the top
    # source: https://github.com/TecharoHQ/anubis/blob/v1.22.0/data/botPolicies.yaml
    #
    ##################
    ## Anubis has the ability to let you import snippets of configuration into the main
    ## configuration file. This allows you to break up your config into smaller parts
    ## that get logically assembled into one big file.
    ##
    ## Of note, a bot rule can either have inline bot configuration or import a
    ## bot config snippet. You cannot do both in a single bot rule.
    ##
    ## Import paths can either be prefixed with (data) to import from the common/shared
    ## rules in the data folder in the Anubis source tree or will point to absolute/relative
    ## paths in your filesystem. If you don't have access to the Anubis source tree, check
    ## /usr/share/docs/anubis/data or in the tarball you extracted Anubis from.

    bots:
      # Kiwix custom rules
      - name: allow-skin-routes
        action: ALLOW
        expression:
          all:
          - path.startsWith("/skin/")
      ##############
      # end of kiwix rules
      ##############
      # Pathological bots to deny
      - # This correlates to data/bots/_deny-pathological.yaml in the source tree
        # https://github.com/TecharoHQ/anubis/blob/main/data/bots/_deny-pathological.yaml
        import: (data)/bots/_deny-pathological.yaml
      - import: (data)/bots/aggressive-brazilian-scrapers.yaml

      # Aggressively block AI/LLM related bots/agents by default
      - import: (data)/meta/ai-block-aggressive.yaml

      # Consider replacing the aggressive AI policy with more selective policies:
      # - import: (data)/meta/ai-block-moderate.yaml
      # - import: (data)/meta/ai-block-permissive.yaml

      # Search engine crawlers to allow, defaults to:
      #   - Google (so they don't try to bypass Anubis)
      #   - Apple
      #   - Bing
      #   - DuckDuckGo
      #   - Qwant
      #   - The Internet Archive
      #   - Kagi
      #   - Marginalia
      #   - Mojeek
      - import: (data)/crawlers/_allow-good.yaml
      # Challenge Firefox AI previews
      - import: (data)/clients/x-firefox-ai.yaml

      # Allow common "keeping the internet working" routes (well-known, favicon, robots.txt)
      - import: (data)/common/keep-internet-working.yaml

      # # Punish any bot with "bot" in the user-agent string
      # # This is known to have a high false-positive rate, use at your own risk
      # - name: generic-bot-catchall
      #   user_agent_regex: (?i:bot|crawler)
      #   action: CHALLENGE
      #   challenge:
      #     difficulty: 16  # impossible
      #     report_as: 4    # lie to the operator
      #     algorithm: slow # intentionally waste CPU cycles and time

      # Requires a subscription to Thoth to use, see
      # https://anubis.techaro.lol/docs/admin/thoth#geoip-based-filtering
      - name: countries-with-aggressive-scrapers
        action: WEIGH
        geoip:
          countries:
            - BR
            - CN
        weight:
          adjust: 10

      # Requires a subscription to Thoth to use, see
      # https://anubis.techaro.lol/docs/admin/thoth#asn-based-filtering
      - name: aggressive-asns-without-functional-abuse-contact
        action: WEIGH
        asns:
          match:
            - 13335 # Cloudflare
            - 136907 # Huawei Cloud
            - 45102 # Alibaba Cloud
        weight:
          adjust: 10

      # ## System load based checks.
      # # If the system is under high load, add weight.
      # - name: high-load-average
      #   action: WEIGH
      #   expression: load_1m >= 10.0 # make sure to end the load comparison in a .0
      #   weight:
      #     adjust: 20

      ## If your backend service is running on the same operating system as Anubis,
      ## you can uncomment this rule to make the challenge easier when the system is
      ## under low load.
      ##
      ## If it is not, remove weight.
      # - name: low-load-average
      #   action: WEIGH
      #   expression: load_15m <= 4.0 # make sure to end the load comparison in a .0
      #   weight:
      #     adjust: -10

      # Generic catchall rule
      - name: generic-browser
        user_agent_regex: >-
          Mozilla|Opera
        action: WEIGH
        weight:
          adjust: 10

    dnsbl: false

    # #
    # impressum:
    #   # Displayed at the bottom of every page rendered by Anubis.
    #   footer: >-
    #     This website is hosted by Zombocom. If you have any complaints or notes
    #     about the service, please contact
    #     <a href="mailto:contact@domainhere.example">contact@domainhere.example</a>
    #     and we will assist you as soon as possible.

    #   # The imprint page that will be linked to at the footer of every Anubis page.
    #   page:
    #     # The HTML <title> of the page
    #     title: Imprint and Privacy Policy
    #     # The HTML contents of the page. The exact contents of this page can
    #     # and will vary by locale. Please consult with a lawyer if you are not
    #     # sure what to put here
    #     body: >-
    #       <p>Last updated: June 2025</p>

    #       <h2>Information that is gathered from visitors</h2>

    #       <p>In common with other websites, log files are stored on the web server saving details such as the visitor's IP address, browser type, referring page and time of visit.</p>

    #       <p>Cookies may be used to remember visitor preferences when interacting with the website.</p>

    #       <p>Where registration is required, the visitor's email and a username will be stored on the server.</p>

    #       <!-- ... -->

    # Open Graph passthrough configuration, see here for more information:
    # https://anubis.techaro.lol/docs/admin/configuration/open-graph/
    openGraph:
      # Enables Open Graph passthrough
      enabled: false
      # Enables the use of the HTTP host in the cache key, this enables
      # caching metadata for multiple http hosts at once.
      considerHost: false
      # How long cached OpenGraph metadata should last in memory
      ttl: 24h
      # # If set, return these opengraph values instead of looking them up with
      # # the target service.
      # #
      # # Correlates to properties in https://ogp.me/
      # override:
      #   # og:title is required, it is the title of the website
      #   "og:title": "Techaro Anubis"
      #   "og:description": >-
      #     Anubis is a Web AI Firewall Utility that helps you fight the bots
      #     away so that you can maintain uptime at work!
      #   "description": >-
      #     Anubis is a Web AI Firewall Utility that helps you fight the bots
      #     away so that you can maintain uptime at work!

    # By default, send HTTP 200 back to clients that either get issued a challenge
    # or a denial. This seems weird, but this is load-bearing due to the fact that
    # the most aggressive scraper bots seem to really, really, want an HTTP 200 and
    # will stop sending requests once they get it.
    status_codes:
      CHALLENGE: 200
      DENY: 200

    # Anubis can store temporary data in one of a few backends. See the storage
    # backends section of the docs for more information:
    #
    # https://anubis.techaro.lol/docs/admin/policies#storage-backends
    store:
      backend: memory
      parameters: {}

    # The weight thresholds for when to trigger individual challenges. Any
    # CHALLENGE will take precedence over this.
    #
    # A threshold has four configuration options:
    #
    #   - name: the name that is reported down the stack and used for metrics
    #   - expression: A CEL expression with the request weight in the variable
    #     weight
    #   - action: the Anubis action to apply, similar to in a bot policy
    #   - challenge: which challenge to send to the user, similar to in a bot policy
    #
    # See https://anubis.techaro.lol/docs/admin/configuration/thresholds for more
    # information.
    thresholds:
      # By default Anubis ships with the following thresholds:
      - name: minimal-suspicion # This client is likely fine, its soul is lighter than a feather
        expression: weight <= 0 # a feather weighs zero units
        action: ALLOW # Allow the traffic through
      # For clients that had some weight reduced through custom rules, give them a
      # lightweight challenge.
      - name: mild-suspicion
        expression:
          all:
            - weight > 0
            - weight < 10
        action: CHALLENGE
        challenge:
          # https://anubis.techaro.lol/docs/admin/configuration/challenges/metarefresh
          algorithm: metarefresh
          difficulty: 1
          report_as: 1
      # For clients that are browser-like but have either gained points from custom rules or
      # report as a standard browser.
      - name: moderate-suspicion
        expression:
          all:
            - weight >= 10
            - weight < 20
        action: CHALLENGE
        challenge:
          # https://anubis.techaro.lol/docs/admin/configuration/challenges/proof-of-work
          algorithm: fast
          difficulty: 2 # two leading zeros, very fast for most clients
          report_as: 2
      # For clients that are browser like and have gained many points from custom rules
      - name: extreme-suspicion
        expression: weight >= 30
        action: CHALLENGE
        challenge:
          # https://anubis.techaro.lol/docs/admin/configuration/challenges/proof-of-work
          algorithm: fast
          difficulty: 4
          report_as: 4
  # not really secret, not exposing port outside
  secret.txt: |
    varnishadmin
  entrypoint.sh: |
    #!/bin/sh
    extra_opts=""
    if [ -z "$VARNISHSIZE" ]; then
      # WARN: uses at least double that amount
      VARNISHSIZE=384M
    fi

    if [ ! -z "$VARNISH_SECRET_PATH" ]; then
      extra_opts="${extra_opts} -S $VARNISH_SECRET_PATH"
    fi

    if [ ! -z "$VARNISH_ADMIN_IP" ]; then
      extra_opts="${extra_opts} -T $VARNISH_ADMIN_IP:6082"
    fi

    if [ -z "$VARNISH_LOG" ]; then
      VARNISH_LOG="/dev/stdout"
    fi

    function varnishncsa_after_varnishd {
      echo "Awaiting varnishd startup "
      while :
      do
        if [ -f /var/run/varnishd.pid ] ; then
          echo ""
          break
        fi
        echo -n "."
        sleep 1
      done
      echo "Varnishd running at PID=$(cat /var/run/varnishd.pid)."

      echo "Starting varnishncsa to record logs to $VARNISH_LOG"
      varnishncsa -D -P /var/run/varnishncsa.pid -c -a -F '%{Host}i %{X-Forwarded-For}i - %u %t "%r" %s %b "%{Referer}i" "%{User-agent}i"' -q 'ReqURL ~ "^/catalog/"' -w $VARNISH_LOG
    }

    varnishncsa_after_varnishd &

    echo "Starting varnish with ${extra_opts}"

    exec varnishd -P /var/run/varnishd.pid -F -a http=:80,HTTP -p feature=+http2 -f /etc/varnish/default.vcl -s default,$VARNISHSIZE $extra_opts
  varnish.vcl: |
    vcl 4.1;

    import std;
    import dynamic;

    # ACL for manual purge requests
    acl purge {
      "localhost";
      "100.64.0.0"/16; // k8s cluster
    }

    # data backend (HTML) is first (and thus default) â€“ and only now
    backend data {
        .host = "demo-library-backend-service";
        .port = "80";

        # .connect_timeout = 60s;
        # .first_byte_timeout = 60s;
        # .between_bytes_timeout = 60s;
    }

    sub vcl_recv {

      if (req.method == "PURGE") {
        if (!client.ip ~ purge) {
          return(synth(403, "Not allowed."));
        }

        # Purge library
        # curl -X PURGE -H "X-Purge-Type: library" localhost
        if (req.http.X-Purge-Type == "library") {
          if (std.ban("req.url ~ ^/catalog/v2/root.xml$") &&
              std.ban("req.url ~ ^/catalog/v2/entries") &&
              std.ban("req.url ~ ^/catalog/v2/partial_entries") &&
              std.ban("req.url ~ ^/catalog/v2/categories") &&
              std.ban("req.url ~ ^/catalog/v2/languages") &&
              std.ban("req.url ~ ^/catalog/v2/search") &&
              std.ban("req.url ~ ^/catalog/root.xml$") &&
              std.ban("req.url ~ ^/catalog/search")) {
            return(synth(200, "Purged Library endpoints"));
          } else {
            # return ban error in 400 response
            return(synth(400, std.ban_error()));
          }
        }

        # Purge for a single Book references with http.X-Book-Id AND req.http.X-Book-Name
        # curl -X PURGE -H "X-Purge-Type: book" -H "X-Book-Id: uuid" -H "X-Book-Name: name" -H "X-Book-Name-Nodate: " localhost
        if (req.http.X-Purge-Type == "book") {
          if (
              # metadata updates
              std.ban("req.url ~ ^/catalog/v2/entry/" + req.http.X-Book-Id) &&
              std.ban("req.url ~ ^/catalog/v2/illustration/" + req.http.X-Book-Id + "/") &&

              # should never change; but can if we redo same ZIM or was 404 before or became 404
              std.ban("req.url ~ ^/raw/" + req.http.X-Book-Name + "/(meta|content)/") &&
              std.ban("req.url ~ ^/content/" + req.http.X-Book-Name) &&

              # may change if kiwix-serve updates search algo/template
              # purging in case ZIM has been updated (should not)
              std.ban("req.url ~ ^/search?content=" + req.http.X-Book-Name + "&") &&

              # may change if kiwix-serve updates suggest algo/template
              # purging in case ZIM has been updated (should not)
              std.ban("req.url ~ ^/suggest?content=" + req.http.X-Book-Name + "&") &&

              # redirects to /content/ (not purging)
              # std.ban("req.url ~ ^/" + req.http.X-Book-Name + "/?$") &&

              # no-date must be purged as redirect may point to a new location
              std.ban("req.url ~ ^/" + req.http.X-Book-Name-Nodate + "/?$") &&
              std.ban("req.url ~ ^/content/" + req.http.X-Book-Name-Nodate + "/?$")) {
            return(synth(200, "Purged Book endpoints"));
          } else {
            # return ban error in 400 response
            return(synth(400, std.ban_error()));
          }
        }

        # curl -X PURGE -H "X-Purge-Type: kiwix-serve" localhost
        if (req.http.X-Purge-Type == "kiwix-serve") {
          if (std.ban("req.url ~ ^/catalog/v2/searchdescription.xml$") &&
              std.ban("req.url ~ ^/skin/") &&
              std.ban("req.url ~ ^/viewer") &&
              std.ban("req.url ~ ^/catalog/searchdescription.xml$") &&
              std.ban("req.url ~ ^/search/searchdescription.xml$") &&
              std.ban("req.url ~ ^/catch/external") &&
              std.ban("req.url ~ ^/$")) {
            return(synth(200, "Purged kiwix-serve endpoints"));
          } else {
            # return ban error in 400 response
            return(synth(400, std.ban_error()));
          }
        }

        return(synth(204, "Missing valid X-Purge-Type"));
      }

      # single backend
      set req.backend_hint = data;

      # remove potential cookie from request (there should be none)
      unset req.http.cookie;

      # set standard proxied ip header for getting original remote address
      # set req.http.X-Forwarded-For = client.ip;
      set req.http.X-Forwarded-For = req.http.x-real-ip;

      # Kiwix-serve 3.4.0 endpoints described at:
      # https://github.com/kiwix/kiwix-tools/issues/498#issuecomment-1337309380

      # library-refresh is triggered by a RESET call initied after our library-refresh script
      # kiwix-serve version change is triggered by a UPDATE call initied on container restart
      # book expiration is triggered by BAN calls for updated/new books after library-refresh script

      # let's cache everything except /random.
      # all endpoints listed above
      if (req.url !~ "^/random") {
          return(hash);
      }

      # default to not caching (to save space)
      return (pass);
    }

    sub vcl_backend_response {

      # make sure to not cache backend errors
      if (beresp.status >= 500 && bereq.is_bgfetch) {
          return (abandon);
      }

      # set ttl to 1d for everything that's returned by backends
      set beresp.ttl = 1d;
      # set beresp.grace = 24h;
      # set beresp.keep = 8m;

      # important for it to go to cache
      unset bereq.http.cookie;
      return (deliver);

    }

---
apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: zim
  labels:
    app: demo-library-frontend-app
  name: demo-library-frontend-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: demo-library-frontend-app
  template:
    metadata:
      labels:
        app: demo-library-frontend-app
    spec:
      securityContext:
        runAsUser: 0
        runAsGroup: 0
      containers:
      - name: anubis
        # WARN: update botPolicies.yaml in cm above copying repo (data/botPolicies.yaml)
        # that's 1.22.0
        image: ghcr.io/techarohq/anubis@sha256:90eb7eab65b28e63bf11f9dedf4b34d599bcaab9d84e8f3d537f027f9ac96c62
        imagePullPolicy: Always
        env:
          - name: "BIND"
            value: ":8080"
          - name: "DIFFICULTY"
            value: "4"
          - name: ED25519_PRIVATE_KEY_HEX
            valueFrom:
              secretKeyRef:
                name: browse-anubis-key
                key: ED25519_PRIVATE_KEY_HEX
          - name: "SERVE_ROBOTS_TXT"
            value: "true"
          - name: "TARGET"
            value: "http://localhost:80"
          - name: "OG_PASSTHROUGH"
            value: "true"
          - name: "OG_EXPIRY_TIME"
            value: "24h"
          - name: "WEBMASTER_EMAIL"
            value: "abuse@kiwix.org"
          - name: "POLICY_FNAME"
            value: "/etc/anubis/botPolicy.yaml"
        volumeMounts:
        - name: configs
          mountPath: "/etc/anubis/botPolicy.yaml"
          subPath: botPolicies.yaml
          readOnly: true
        resources:
          limits:
            cpu: 1000m
            memory: 10Gi
          requests:
            cpu: 250m
            memory: 10Gi
        securityContext:
          runAsUser: 1000
          runAsGroup: 1000
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
          seccompProfile:
            type: RuntimeDefault
      - image: docker.io/library/varnish:7.3-alpine
        # command: ["varnishd", "-F", "-a", "http=:80,HTTP", "-p", "feature=+http2", "-f", "/etc/varnish/default.vcl", "-s", "malloc,384M"]
        command: ["entrypoint"]
        imagePullPolicy: IfNotPresent
        name: varnish
        env:
        - name: VARNISHSIZE
          value: "8G"
        - name: VARNISH_SECRET_PATH
          value: /etc/varnish/secret
        - name: VARNISH_ADMIN_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: VARNISH_LOG
          value: "/data/logs/access.log"
        ports:
        - containerPort: 80
        - containerPort: 6082
        volumeMounts:
        - name: configs
          mountPath: "/usr/sbin/entrypoint"
          subPath: entrypoint.sh
          readOnly: true
        - name: configs
          mountPath: "/etc/varnish/secret"
          subPath: secret.txt
          readOnly: true
        - name: configs
          mountPath: "/etc/varnish/default.vcl"
          subPath: varnish.vcl
          readOnly: true
        - mountPath: "/data/logs"
          subPath: demo-library-kiwix
          name: nginx-logs-volume
          readOnly: false
        resources:
          requests:
            memory: "12Gi"
            cpu: "30m"
      volumes:
      - name: configs
        configMap:
          name: demo-library-frontend-configs
          defaultMode: 0755
      - name: nginx-logs-volume
        persistentVolumeClaim:
          claimName: nginx-logs-pvc
      nodeSelector:
        k8s.kiwix.org/role: "storage"
---
apiVersion: v1
kind: Service
metadata:
  namespace: zim
  name: demo-library-frontend-service
  labels:
    app: demo-library-frontend-app
spec:
  selector:
    app: demo-library-frontend-app
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
  - name: varnishadm
    protocol: TCP
    port: 6082
    targetPort: 6082
  - protocol: TCP
    port: 8080
    targetPort: 8080
    name: anubis
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: demo-library-frontend-ingress
  namespace: zim
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/server-snippet: |
        location /robots.txt {
          add_header Content-Type "text/plain";
          return 200 "User-agent: *\nDisallow: /";
        }
spec:
  ingressClassName: nginx
  tls:
    - hosts:
      - browse.library.kiwix.org
      secretName: browse-library-kiwix-org-tls
  rules:
  - host: browse.library.kiwix.org
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: demo-library-frontend-service
            port:
              name: anubis
